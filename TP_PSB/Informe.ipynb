{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# Trabajo Práctico Final\n",
    "\n",
    "## Procesamiento de señales biomédicas\n",
    "\n",
    "### Primer Cuatrimestre 2024\n",
    "\n",
    "</center>\n",
    "\n",
    "**Docentes:**\n",
    "\n",
    "- Roberto Sebastián Tomás\n",
    "- Aylin Agatha Vazquez Chenlo\n",
    "- Francisco Tassara\n",
    "- Victoria Reppucci\n",
    "\n",
    "**Alumnxs:**\n",
    "\n",
    "- Bajlec, Ivo - 62175\n",
    "- Grau, Gonzalo - 62259\n",
    "- Pereira, Camila Noemi - 61574"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo del trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del presente trabajo es desarrollar un algoritmo, implementado los conocimientos obtenidos en las clases teóricas, que nos permita obtener una medida que sea lo más objetiva posible sobre la percepción sonora. Para realizar esto, el algoritmo que se desarrolló, se busco que sea capaz de procesar las información de los potenciales evocados, por medio de los cuatro tipos de promedios: homogéneo, inhomogéneo con amplitud variable, inhomogéneo con varianza variable e inhomogéneo con amplitud y varianza variable, y con la implementación de diferentes métodos como welch, interpretar esa información obtenida como un nivel de percepción sonora.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estado del arte "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los potenciales evocados son pruebas diagnósticas que evalúan la integridad de las vías sensitivas a través de la estimulación sensorial, en este caso auditiva, y el registro de las respuestas cerebrales. Dichas respuestas, se registran mediante estímulos repetitivos y se promedian para mejorar la relación señal-ruido, permitiendo una evaluación más precisa de las vías neuronales estimuladas. Link = https://www.cun.es/enfermedades-tratamientos/pruebas-diagnosticas/potenciales-evocados\n",
    "\n",
    "**Tipos de potenciales evocados:**\n",
    "1) Emisiones otoacústicas (OAE): este tipo de sonidos son emitidos por el oído interno, precisamente por las células ciliadas externas de la cóclea, como respuesta a un estímulo auditivo. Estas emisiones se utilizan para evaluar la función coclear, además de resultar útiles para la detección temprana de la pérdida auditiva. Métodos como las emisiones otoacústicas transitorias, que se basan en OAE, son utilizadas para estimar el crecimiento de la sonoridad.\n",
    "\n",
    "2) Respuestas auditivas evocadas del tronco del encéfalo (ABR): este tipo de potenciales son generados por la actividad neural en el tronco del encéfalo en respuesta a estímulos auditivos. Los ABR reflejan la actividad neural desde el nervio auditivo hasta el tronco del encéfalo. Las grabaciones de ABR, se utilizan para evaluar la audición y la integridad de las vías auditivas centrales, siendo útiles para estimar el umbral auditivo y detectar problemas neurológicos que puedan afectar las vías auditivas. Otro método también utilizado es el de las ABR con explosiones de tonos (TBABR),  que sirve para estimar el crecimiento de la sonoridad en relación con la intensidad del estímulo.\n",
    "\n",
    "**Tálamo**\n",
    "\n",
    "Para el procesamiento de los potenciales evocados, el tálamo termina resultando ser una estructura clave debido a que actúa como un relevo para la información sensorial que se dirige hacia la corteza cerebral. En particular, las señales auditivas, pasan por el núcleo geniculado medial del tálamo antes de llegar a la corteza. Esta vía, termina resultando fundamental para la percepción auditiva y la integración sensorial, de esta manera el cerebro puede procesar y responder a los estímulos auditivos. Links = https://www.fisioterapia-online.com/glosario/talamo-o-estructura-del-cerebro y https://www.cochlea.eu/es/cerebro-auditivo/talamo-corteza#:~:text=El%20t%C3%A1lamo%20auditivo%2C%20Cuerpo%20Geniculado,ascendentes%20al%20cortex%20auditivo%20primario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar nuestro trabajo, la cátedra nos proporcionó una base de datos disponible en https://physionet.org/content/earndb/1.0.0/ , que fue creada y aportada por Michael J.Epstein e Ikaro Silva. La base fue generada como parte de un estudio sobre potenciales evocados y el crecimiento de la sonoridad, esta cuenta con dos conjuntos de señales fisiológicas: ABR y OAE que se registraron en conjunto en una cabina insonorizada y eléctricamente blindada, y dos conjuntos de estimaciones psicoacústicas de la sonoridad en función del nivel de presión sonora pico (peSPL).\n",
    "\n",
    "Además de los datos sin procesar, se realizaron para cada nivel dos promedios ponderados de las grabaciones de ABR y OAE, el primero consistió en la media ponderada de todas las pruebas de la primera mitad y el segundo de todas las pruebas de la segunda mitad. Para cada frecuencia, el estímulo se presentó en forma creciente desde el umbral de oyente, que se determinó a partir del umbral máximo del procedimiento CMM o ME, hasta los 100 dB peSPL en pasos de 5 dB.\n",
    "\n",
    "Los archivos para cada sujeto NX que se obtuvieron fueron los siguientes:\n",
    "\n",
    "Datos promediados:\n",
    "- Nx_evoked_avelevel_Ffreq_Rrep.dat: archivo binario con señales ABR y OAE.\n",
    "- Nx_evoked_avelevel_Ffreq_Rrep.hea: archivo de encabezado con comentarios sobre sexo, oido presentado, edad del sujeto, numero de pruebas utilizadas en el prmedio, nivel de ruido residual estimado y relacion señal ruido ponderada estimada.\n",
    "- Nx_LoudnessData_Ffreq.txt: mediciones de sonoridad en unidades logarítmicas obtenidas mediante procedimientos psicoacústicos.\n",
    "\n",
    "Datos sin procesar: \n",
    "- Nx_evoked_rawlevel_Ffreq_Rrep.dat: archivo binario con señales ABR y OAE.\n",
    "- Nx_evoked_rawlevel_Freq_ Rrep.hea: archivo de encabezado con comentarios sobre nivel de estímulo, frecuencia del estímulo, oído presentado, longitud de la prueba y condición.\n",
    "- Nx_evoked_rawlevel_Ffreq_Rrep.trg: archivo binario de anotación que indica el inicio de la prueba con respecto al inicio del estímulo.\n",
    "\n",
    "Aclaraciones: x representa el ID del oyente (1 al 8), level = peSPL del estímulo (Este es el que va aumentando desde el umbral hasta 100 dB en pasos de 5dB), freq = frecuencia del estímulo en kHz y rep = 1 o 2 indicando que promedio representa. Además, en el 20% de los casos, ocurrió que uno de los canales estaba severamente dañado por artefactos eléctricos y se lo eliminó de los archivos (los nombres de los archivos finalizar con _x).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materiales y métodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el desarrollo de este trabajo, se hará uso de los siguientes módulos de código abierto:\n",
    "- numpy\n",
    "- matplotlib\n",
    "- pandas\n",
    "- scipy\n",
    "\n",
    "Además, se desarrollaron dos módulos propios que se encuentran disponibles en los archivos _data\\_hea\\_reader.py_ y _eeg\\_avg.py_. En el caso de _data\\_hea\\_reader.py_, este archivo contiene funciones que permiten leer y procesar datos de señales EEG desde archivos que se encuentran en formato '.dat' y '.hea'. Y respecto al archivo _eeg\\_avg.py_, este contiene funciones que permite simular y analizar potenciales evocados relacionados con eventos a partir de señales de EEG.\n",
    "\n",
    "En base a nuestro objetivo, el procedimiento aplicado consiste de los siguientes pasos:\n",
    "\n",
    "1) .....\n",
    "2) .....\n",
    "3) .....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por su utilizando a posterior, se comienza brindando una explicación de los dos modulos propios que se desarrollaron. Como se mencionó en el apartado de \"Materiales y métodos\", estos modulos son _data\\_hea\\_reader.py_ y _eeg\\_avg.py_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo  _data\\_hea\\_reader.py_ es un código que incluye funciones que permiten la lectura y el procesamiento de  datos de señales EEG que se encuentran almacenados en formatos especificos. Esto termina facilitando el posterior análisis de las señales.\n",
    "\n",
    "Las funciones que presenta son dos: parse_comments() y read_trials(). La primera permite la conversión a un diccionario de los comentarios que estan presentes en los archivos '.hea'; y la segunda permite que a partir de la lectura de los archivos '.dat' y'.hea', se extraigan las señales de EEG. Esta segunda funcion termina devolviendo la frecuencia de muestreo, una matriz de segmentos válidos y el diccionario de comentarios porque utiliza la primera función mencionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_comments(comments: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Reads the 'comments' section of the trial .hea file into a dictionary\n",
    "    \"\"\"\n",
    "    INT_KEYS = ['SPL', 'Stim Freq (kHz)', 'Trial Length (samples)']\n",
    "    comments = comments[0]\n",
    "    pattern = r'<([^>]+)>: ([^<]+)'\n",
    "    matches = re.findall(pattern, comments)\n",
    "    parsed_dict = {key.strip(): value.strip() for key, value in matches}\n",
    "    \n",
    "    for key in INT_KEYS:\n",
    "        try:\n",
    "            parsed_dict[key] = int(parsed_dict[key])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Invalid data type for {key} : {parsed_dict[key]}\")\n",
    "        \n",
    "    return parsed_dict\n",
    "\n",
    "\n",
    "def read_trials(filepath: str, threshold: int=50000) -> Tuple[int, np.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Reads .dat and .hea files, and the\n",
    "\n",
    "    Args:\n",
    "        filepath (str): filepath WITHOUT the extension\n",
    "        threshold (int): voltage threshold in nV to discard measuring artifacts\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, np.ndarray, dict]: sample frequency, trials matrix, comments dict\n",
    "    \"\"\"\n",
    "\n",
    "    record = wfdb.rdrecord(filepath)\n",
    "    fs = record.fs\n",
    "    ABR_raw = record.p_signal[:, 0]\n",
    "    comments = parse_comments(record.comments)\n",
    "    tr_len = comments['Trial Length (samples)']\n",
    "    sig_len = record.sig_len\n",
    "\n",
    "    #create an empty list\n",
    "    trials = []\n",
    "    for i in range(0, sig_len - tr_len, tr_len):\n",
    "        #separate a trial \n",
    "        trial = ABR_raw[i:i+tr_len]\n",
    "        #check if the trial has some outlier data, if it does the trial is discarted\n",
    "        if any(abs(point) > threshold for point in trial):\n",
    "            continue\n",
    "        else:\n",
    "            trials.append(trial)\n",
    "            \n",
    "    if not trials:\n",
    "            raise ValueError(\"Todos los trials estan fuera del limite, ende Trials esta vacia\")\n",
    "    \n",
    "    trials = np.array(trials)\n",
    "\n",
    "    return fs, trials, comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo _eeg\\_avg.py_ que posee un código que incluye funciones que permiten la simulación y el análisis de señales ERP en EEG, de esta manera, facilita la comparación de diferentes métodos de promediado.\n",
    "\n",
    "Se puede observar en este archivos tres funciones en total, dos de ellas funcionales y la tercera como prueba de las anteriores, estas funciones son: simulate_ERP(), average_EEG () y test().\n",
    "\n",
    "La función simulate_ERP(), realiza una simulación de lectura ERP EEG donde la amplitud y/o la varianza resultan parametros variables segun el modo (homogéneo, inhomogéneo con amplitud variable, inhomogéneo con varianza variable e inhomogéneo con amplitud y varianza variable). De esta función se obtiene un arreglo de tiempo, una matriz de señales EEG, y la señal ERP promedio.\n",
    "\n",
    "Con respecto a la función average_EEG(), esta ejecuta un promedio ponderado o no ponderado de una serie de señales ERP EEG, por lo tanto, termina devolviendo un arreglo con la señales promediadas.\n",
    "\n",
    "Por ultimo, la función test() sirve como para probar simulando señales ERP y realizando los promedios en sus cuatro modos, y luego grafica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ERP(fs: int=250, \n",
    "                 latency: int=100,\n",
    "                 N_exp: int=5,\n",
    "                 plotting: bool=True,\n",
    "                 vary: str='homogenous') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulates a series of ERP EEG readings, with varying amplitude and/or variance\n",
    "\n",
    "    Args:\n",
    "        fs (int, optional): sampling frecuency. Defaults to 250\n",
    "        latency (int, optional): latency of ERP. Defaults to 100.\n",
    "        N_exp (int, optional): Number of independent experiments. Defaults to 5.\n",
    "        plotting (bool, optional): Indicates wheteher or not to plot the EEGs. Defaults to True.\n",
    "        mode (str, optional): Indicates how to vary either amplitude of noise variance:\n",
    "            - 'homogenous': same amplitude and variance for all experiments\n",
    "            - 'amp': varies amplitude with every experiment\n",
    "            - 'var': varies noise variance for every experiment\n",
    "            - 'both': vary both amplitude and noise variance\n",
    "        Defaults to 'homogenous'\n",
    "\n",
    "        Returns: X, a matrix where every row is a new experiment and every column is a new sample\n",
    "\n",
    "    \"\"\"\n",
    "    lat = latency*(10**-3)*fs\n",
    "    t_ERP = np.linspace(0, 0.2, int(fs*0.2))\n",
    "\n",
    "    VALID_VARY = {'homogenous', 'amp', 'var', 'both'}\n",
    "    if vary not in {'homogenous', 'amp', 'var', 'both'}:\n",
    "        raise ValueError(F\"{vary} is not a valid mode. Should be: {''.join(VALID_VARY)}\")\n",
    "\n",
    "    elif vary == 'homogenous' or vary == 'var':\n",
    "        erp = 20*np.sin(100*t_ERP)*np.exp(-30*t_ERP)\n",
    "        erp = erp/np.max(erp)\n",
    "        l = np.zeros([1, int(lat)])\n",
    "        s = np.append(l, erp)\n",
    "        end = np.zeros([1, fs-s.shape[0]])\n",
    "        sig = np.append(s, end)\n",
    "        erp_signal = sig.copy()\n",
    "        eeg = []\n",
    "        for i in range(N_exp):\n",
    "            eeg.append(erp_signal)\n",
    "        eeg = np.array(eeg)\n",
    "\n",
    "    elif vary == 'amp' or vary == 'both':\n",
    "        eeg = []\n",
    "        for i in range(N_exp):\n",
    "            erp = (5+5*abs(np.random.randn(1)[0])) * np.sin(100*t_ERP)*np.exp(-30*t_ERP)\n",
    "            l = np.zeros([1, int(lat)])\n",
    "            s = np.append(l, erp)\n",
    "            end = np.zeros([1, fs-s.shape[0]])\n",
    "            sig = np.append(s, end)\n",
    "            eeg.append(sig)\n",
    "        eeg = np.array(eeg)\n",
    "        eeg = eeg/(0.1*np.max(eeg))\n",
    "        erp_signal = np.mean(eeg, axis=0)\n",
    "\n",
    "    if vary == 'homogenous' or vary == 'amp':\n",
    "        for i in range(N_exp):\n",
    "            noise = 10*np.random.randn(sig.shape[0])\n",
    "            eeg[i,:] = eeg[i,:] + noise\n",
    "    elif vary == 'var' or vary == 'both':\n",
    "        for i in range(N_exp):\n",
    "            noise = (5+3*abs(np.random.randn(1)[0])) * np.random.randn(sig.shape[0])\n",
    "            eeg[i,:] = eeg[i,:] + noise\n",
    "\n",
    "    t_eeg = np.linspace(0, eeg.shape[1]/fs, eeg.shape[1])\n",
    "\n",
    "    if plotting:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        for i in range(N_exp):\n",
    "            plt.plot(t_eeg, eeg[i]-i*50)\n",
    "        plt.title('Realizaciones')\n",
    "        plt.ylabel('Amplitud [uV]')\n",
    "        plt.xlabel('Tiempo [s]')\n",
    "        plt.show()\n",
    "\n",
    "    return t_eeg, eeg, erp_signal\n",
    "\n",
    "def average_EEG(X: np.ndarray, mode: str='homgenous') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs a weighted or unweighted average of series of ERP EEG signals\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): NxM matrix where every row is a new experiment and every column is a new sample\n",
    "        mode (str, optional): Indicates how to perform the average. Could be:\n",
    "            - homogenous: simple, unweighted average\n",
    "            - amp: weight by amplitude\n",
    "            - var: weight by variance\n",
    "            - both: weight by both amplitude and variance\n",
    "        Defaults to 'homogenous'.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: an Mx1 array with the averaged signals\n",
    "    \"\"\"\n",
    "    VALID_MODE = {'homogenous', 'amp', 'var', 'both'}\n",
    "    if mode not in {'homogenous', 'amp', 'var', 'both'}:\n",
    "        raise ValueError(F\"{mode} is not a valid mode. Should be: {''.join(VALID_MODE)}\")\n",
    "\n",
    "    elif mode == 'homogenous':\n",
    "        return np.mean(X, axis=0)\n",
    "    \n",
    "    # Find amplitudes\n",
    "    s = np.mean(X, axis = 0)\n",
    "    a = X.dot(s.T)\n",
    "\n",
    "    # Find variances\n",
    "    M = X.shape[1]\n",
    "    V = np.var(X[:, -int(0.4*M):], axis=1)\n",
    "\n",
    "    # Get weights and average\n",
    "    if mode == 'amp':\n",
    "        w = a / np.sum(a**2)\n",
    "    elif mode == 'var':\n",
    "        w = (1/V) / (np.sum(1/V))\n",
    "    elif mode == 'both':\n",
    "        w = (a/V) / (np.sum(a**2/V))\n",
    "    \n",
    "    return w.T.dot(X/np.sum(w))\n",
    "\n",
    "\n",
    "def test():\n",
    "    t, X, pe = simulate_ERP(N_exp = 200, vary='both' , plotting=False)\n",
    "\n",
    "    X_mean = average_EEG(X, mode='homogenous') \n",
    "    X_amp = average_EEG(X, mode='amp')\n",
    "    X_var = average_EEG(X, mode='var')\n",
    "    X_both = average_EEG(X, mode='both')\n",
    "\n",
    "    plt.figure(figsize = (20,10))\n",
    "    plt.plot(t, X_mean, label='Promediado homogeneo')\n",
    "    plt.plot(t, X_amp, label='Promedio inhomogéneo amplitud variable')\n",
    "    plt.plot(t, X_var, label='Promedio homogéneo varianza variable')\n",
    "    plt.plot(t, X_both, label='Promedio inhomogéneo todo variable')\n",
    "    plt.plot(t, pe, color='black', label='Potencial Evocado teorico')\n",
    "    plt.title('Métodos de promediado')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A partir de la base de datos otorgada, para el realizar el trabajo se decidió utilizar al sujeto N1. Lo que buscamos en un comienzo, con el fin de facilitar los posteriores análisis, es automatizar el promesamiento y análisis de grandes conjuntos de datos de EEG. Se realizó un procesamiento de archivos de datos de EEG, se calculó el promedio de la señales con los cuatro modos mencionados y se guardaron los resultados en archivos en formato CSV. Para esto se utilizaron las siguiente librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dat_hea_reader import *\n",
    "from eeg_avg import *\n",
    "import scipy.signal as sig\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y este es código que realiza lo mencionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    lista_paths=[]\n",
    "    directory = os.fsencode('data_raw_N1')\n",
    "    lista_SPL = []\n",
    "    spl_pattern = re.compile(r'(raw_)(\\d*)(_F)')\n",
    "\n",
    "    print('Buscando archivos')\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".dat\"):\n",
    "            # Join the bytes path of the directory with the string filename\n",
    "            filepath = os.path.join(directory, os.fsencode(filename))\n",
    "            # Decode the filepath for printing\n",
    "            name = os.fsdecode(filepath)\n",
    "            lista_paths.append(name[:-4]) # Remove extension\n",
    "            pattern = re.compile(r'(raw_)(\\d*)(_F)')\n",
    "            spl = re.search(pattern, name).group(2)\n",
    "            lista_SPL.append(int(spl))\n",
    "    \n",
    "    cant_files = len(lista_paths)\n",
    "\n",
    "    #para sacar datos sobre el tr_len y el tipo de dato\n",
    "    fs, trials, comments = read_trials(lista_paths[0])\n",
    "    tr_len = comments['Trial Length (samples)']\n",
    "\n",
    "    #se crean matrices de zeros que despues cada fila se rellena con el promeio de un archivo\n",
    "    mat_trials_mean = np.zeros((cant_files,tr_len),dtype=trials.dtype)\n",
    "    mat_trials_amp = np.zeros((cant_files,tr_len),dtype=trials.dtype)\n",
    "    mat_trials_var = np.zeros((cant_files,tr_len),dtype=trials.dtype)\n",
    "    mat_trials_both = np.zeros((cant_files,tr_len),dtype=trials.dtype)\n",
    "\n",
    "    #se recorren todos los archivos haciendo el priomedio de cada uno y llenando las matrices \n",
    "    print('Promediando...')\n",
    "    for i, file in enumerate(lista_paths):\n",
    "        try:\n",
    "            fs, trials, comments = read_trials(file)\n",
    "\n",
    "            trials_mean = average_EEG(trials, mode='homogenous') \n",
    "            mat_trials_mean[i,:] = trials_mean\n",
    "\n",
    "            trials_amp = average_EEG(trials, mode='amp')\n",
    "            mat_trials_amp[i,:] = trials_amp\n",
    "\n",
    "            trials_var = average_EEG(trials, mode='var')\n",
    "            mat_trials_var[i,:] = trials_var\n",
    "\n",
    "            trials_both = average_EEG(trials, mode='both')\n",
    "            mat_trials_both[i,:] = trials_both\n",
    "\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"error con el archivo {file}\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # Mando a csv\n",
    "    filenames = ['homo', 'amp', 'var', 'both']\n",
    "    output_dir = 'data_avg_N1'\n",
    "    row_names = np.array(lista_SPL)\n",
    "    \n",
    "    print('Guardando a csv...')\n",
    "    for data, fname in zip([mat_trials_mean, mat_trials_amp, mat_trials_var, mat_trials_both], filenames):\n",
    "        sorted_indices = row_names.argsort()[::-1]\n",
    "        sorted_data = data[sorted_indices]\n",
    "        df = pd.DataFrame(sorted_data.T)\n",
    "        df.to_csv(rf\"{output_dir}/promedios_{fname}.csv\", index=False, header=row_names[sorted_indices])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
